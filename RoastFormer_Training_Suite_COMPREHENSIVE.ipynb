{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ RoastFormer Comprehensive Training Suite - FIXED\n",
    "\n",
    "**Complete Ablation Studies with Normalization Fix**\n",
    "\n",
    "Author: Charlee Kraiss  \n",
    "Project: RoastFormer - Transformer-Based Roast Profile Generation  \n",
    "Date: November 19, 2024\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ What This Notebook Does\n",
    "\n",
    "1. âœ… Runs ALL scientific experiments with normalization fix\n",
    "2. âœ… Positional encoding ablation (Sinusoidal vs Learned vs **RoPE**)\n",
    "3. âœ… Flavor conditioning ablation (validates novel contribution)\n",
    "4. âœ… Model size comparison\n",
    "5. âœ… Optional: Before/after fix comparison\n",
    "6. âœ… Compatible checkpoints for evaluation demo\n",
    "\n",
    "**ğŸ”§ THE FIX**: Temperature normalization to [0, 1] range\n",
    "\n",
    "**Experiments Available:**\n",
    "- **Tier 1 (Model Size)**: micro (d=32), tiny (d=64), medium (d=128)\n",
    "- **Tier 2 (Positional Encoding)**: sinusoidal, learned, **RoPE**\n",
    "- **Tier 3 (Ablation)**: with/without flavor conditioning\n",
    "- **Tier 4 (Debugging)**: broken model comparison\n",
    "\n",
    "**Est. Runtime**: 1-3 hours on GPU (depends on selection)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(\"=\"*80)\n",
    "print(\"GPU CHECK\")\n",
    "print(\"=\"*80)\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    device = 'cuda'\n",
    "    print(\"âœ… GPU ready!\")\n",
    "else:\n",
    "    print(\"âš ï¸  No GPU - Go to Runtime â†’ Change runtime type â†’ GPU\")\n",
    "    device = 'cpu'\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install -q pandas scikit-learn matplotlib seaborn numpy\n",
    "print(\"âœ… Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to project\n",
    "%cd /content/gdrive/MyDrive/\"Colab Notebooks\"/\"GEN_AI\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import json\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EXTRACTING DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "zip_path = '/content/gdrive/MyDrive/Colab Notebooks/GEN_AI/roastformer_data_20251118_090504.zip'\n",
    "\n",
    "if os.path.exists(zip_path):\n",
    "    os.chdir('/content')\n",
    "    print(f\"Working directory: {os.getcwd()}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“¦ Extracting...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "    \n",
    "    print(\"âœ… Extraction complete\")\n",
    "    \n",
    "    with open('preprocessed_data/dataset_stats.json', 'r') as f:\n",
    "        stats = json.load(f)\n",
    "    print(f\"\\nğŸ“Š Dataset: {stats['total_profiles']} profiles\")\n",
    "    print(f\"   Training: {stats['train_size']}\")\n",
    "    print(f\"   Validation: {stats['val_size']}\")\n",
    "else:\n",
    "    print(f\"âŒ Zip not found at: {zip_path}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ EXPERIMENT CONFIGURATION HUB\n",
    "\n",
    "**ğŸ‘‰ CONFIGURE YOUR EXPERIMENTS HERE ğŸ‘ˆ**\n",
    "\n",
    "### Tier 1: Model Size Comparison âœ…\n",
    "All use sinusoidal PE, with flavors, with normalization\n",
    "- `micro_d32`: Fast baseline (d=32, ~45K params, 10 min)\n",
    "- `tiny_d64`: Production model (d=64, ~218K params, 20 min)\n",
    "- `medium_d128`: Best accuracy (d=128, ~1M params, 40 min)\n",
    "\n",
    "### Tier 2: Positional Encoding Ablation âœ…\n",
    "All use d=64 for fair comparison\n",
    "- `sinusoidal_pe`: Baseline (already in tiny_d64)\n",
    "- `learned_pe`: Learned positional embeddings\n",
    "- `rope_pe`: **RoPE** (you presented on this!)\n",
    "\n",
    "### Tier 3: Flavor Conditioning Ablation âœ…\n",
    "Tests your novel contribution\n",
    "- `with_flavors`: Baseline (already in tiny_d64)\n",
    "- `no_flavors`: Remove flavor features\n",
    "\n",
    "### Tier 4: Debugging Comparison (Optional)\n",
    "- `broken_model`: Without normalization (shows bug for presentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXPERIMENT CONFIGURATION HUB\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "EXPERIMENTS = {\n",
    "    # â”€â”€â”€ TIER 1: MODEL SIZE COMPARISON â”€â”€â”€\n",
    "    'micro_d32': True,           # Fast baseline (10 min)\n",
    "    'tiny_d64': True,            # Production model (20 min)\n",
    "    'medium_d128': True,         # Best accuracy (40 min)\n",
    "    \n",
    "    # â”€â”€â”€ TIER 2: POSITIONAL ENCODING ABLATION â”€â”€â”€\n",
    "    'learned_pe': True,          # Learned PE (20 min)\n",
    "    'rope_pe': True,             # RoPE - YOU PRESENTED ON THIS! (20 min)\n",
    "    # Note: tiny_d64 serves as sinusoidal baseline\n",
    "    \n",
    "    # â”€â”€â”€ TIER 3: FLAVOR ABLATION â”€â”€â”€\n",
    "    'no_flavors': True,          # Tests novel contribution (20 min)\n",
    "    # Note: tiny_d64 serves as with-flavors baseline\n",
    "    \n",
    "    # â”€â”€â”€ TIER 4: DEBUGGING COMPARISON â”€â”€â”€\n",
    "    'broken_model': False,       # Without normalization (20 min) - Enable for presentation\n",
    "}\n",
    "\n",
    "# Base configuration (shared across all experiments)\n",
    "BASE_CONFIG = {\n",
    "    # Architecture defaults (overridden per experiment)\n",
    "    'd_model': 64,\n",
    "    'nhead': 4,\n",
    "    'num_layers': 3,\n",
    "    'dim_feedforward': 256,\n",
    "    'embed_dim': 32,\n",
    "    'dropout': 0.2,\n",
    "    'positional_encoding': 'sinusoidal',\n",
    "    \n",
    "    # Training hyperparameters (same for all)\n",
    "    'batch_size': 8,\n",
    "    'num_epochs': 20,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 0.01,\n",
    "    'grad_clip': 1.0,\n",
    "    'early_stopping_patience': 15,\n",
    "    'max_sequence_length': 800,\n",
    "    \n",
    "    # System\n",
    "    'device': device,\n",
    "    'preprocessed_dir': 'preprocessed_data',\n",
    "    'save_every': 5,\n",
    "    \n",
    "    # Fix settings\n",
    "    'use_normalization': True,\n",
    "    'use_flavors': True,\n",
    "}\n",
    "\n",
    "# Generate experiment configs\n",
    "experiment_configs = {}\n",
    "\n",
    "# â”€â”€â”€ TIER 1: MODEL SIZE â”€â”€â”€\n",
    "if EXPERIMENTS['micro_d32']:\n",
    "    config = BASE_CONFIG.copy()\n",
    "    config.update({\n",
    "        'd_model': 32,\n",
    "        'nhead': 2,\n",
    "        'num_layers': 2,\n",
    "        'dim_feedforward': 128,\n",
    "        'num_epochs': 15,\n",
    "        'experiment_name': 'micro_d32_sinusoidal_with_flavors',\n",
    "        'checkpoint_dir': 'checkpoints/micro_d32',\n",
    "        'results_dir': 'results/micro_d32',\n",
    "    })\n",
    "    experiment_configs['micro_d32'] = config\n",
    "\n",
    "if EXPERIMENTS['tiny_d64']:\n",
    "    config = BASE_CONFIG.copy()\n",
    "    config.update({\n",
    "        'd_model': 64,\n",
    "        'nhead': 4,\n",
    "        'num_layers': 3,\n",
    "        'dim_feedforward': 256,\n",
    "        'num_epochs': 20,\n",
    "        'experiment_name': 'tiny_d64_sinusoidal_with_flavors',\n",
    "        'checkpoint_dir': 'checkpoints/tiny_d64',\n",
    "        'results_dir': 'results/tiny_d64',\n",
    "    })\n",
    "    experiment_configs['tiny_d64'] = config\n",
    "\n",
    "if EXPERIMENTS['medium_d128']:\n",
    "    config = BASE_CONFIG.copy()\n",
    "    config.update({\n",
    "        'd_model': 128,\n",
    "        'nhead': 4,\n",
    "        'num_layers': 4,\n",
    "        'dim_feedforward': 512,\n",
    "        'num_epochs': 25,\n",
    "        'experiment_name': 'medium_d128_sinusoidal_with_flavors',\n",
    "        'checkpoint_dir': 'checkpoints/medium_d128',\n",
    "        'results_dir': 'results/medium_d128',\n",
    "    })\n",
    "    experiment_configs['medium_d128'] = config\n",
    "\n",
    "# â”€â”€â”€ TIER 2: POSITIONAL ENCODING â”€â”€â”€\n",
    "if EXPERIMENTS['learned_pe']:\n",
    "    config = BASE_CONFIG.copy()\n",
    "    config.update({\n",
    "        'd_model': 64,\n",
    "        'positional_encoding': 'learned',\n",
    "        'num_epochs': 20,\n",
    "        'experiment_name': 'tiny_d64_LEARNED_with_flavors',\n",
    "        'checkpoint_dir': 'checkpoints/learned_pe',\n",
    "        'results_dir': 'results/learned_pe',\n",
    "    })\n",
    "    experiment_configs['learned_pe'] = config\n",
    "\n",
    "if EXPERIMENTS['rope_pe']:\n",
    "    config = BASE_CONFIG.copy()\n",
    "    config.update({\n",
    "        'd_model': 64,\n",
    "        'positional_encoding': 'rope',\n",
    "        'num_epochs': 20,\n",
    "        'experiment_name': 'tiny_d64_ROPE_with_flavors',\n",
    "        'checkpoint_dir': 'checkpoints/rope_pe',\n",
    "        'results_dir': 'results/rope_pe',\n",
    "    })\n",
    "    experiment_configs['rope_pe'] = config\n",
    "\n",
    "# â”€â”€â”€ TIER 3: FLAVOR ABLATION â”€â”€â”€\n",
    "if EXPERIMENTS['no_flavors']:\n",
    "    config = BASE_CONFIG.copy()\n",
    "    config.update({\n",
    "        'd_model': 64,\n",
    "        'use_flavors': False,  # KEY DIFFERENCE\n",
    "        'num_epochs': 20,\n",
    "        'experiment_name': 'tiny_d64_sinusoidal_NO_FLAVORS',\n",
    "        'checkpoint_dir': 'checkpoints/no_flavors',\n",
    "        'results_dir': 'results/no_flavors',\n",
    "    })\n",
    "    experiment_configs['no_flavors'] = config\n",
    "\n",
    "# â”€â”€â”€ TIER 4: DEBUGGING â”€â”€â”€\n",
    "if EXPERIMENTS['broken_model']:\n",
    "    config = BASE_CONFIG.copy()\n",
    "    config.update({\n",
    "        'd_model': 64,\n",
    "        'use_normalization': False,  # NO FIX\n",
    "        'num_epochs': 20,\n",
    "        'experiment_name': 'tiny_d64_BROKEN_no_normalization',\n",
    "        'checkpoint_dir': 'checkpoints/broken',\n",
    "        'results_dir': 'results/broken',\n",
    "    })\n",
    "    experiment_configs['broken_model'] = config\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PRINT EXPERIMENT PLAN\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE EXPERIMENT PLAN\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal experiments: {len(experiment_configs)}\")\n",
    "\n",
    "# Group by tier\n",
    "tier1 = [k for k in ['micro_d32', 'tiny_d64', 'medium_d128'] if k in experiment_configs]\n",
    "tier2 = [k for k in ['learned_pe', 'rope_pe'] if k in experiment_configs]\n",
    "tier3 = [k for k in ['no_flavors'] if k in experiment_configs]\n",
    "tier4 = [k for k in ['broken_model'] if k in experiment_configs]\n",
    "\n",
    "if tier1:\n",
    "    print(f\"\\nğŸ”¬ TIER 1: Model Size Comparison ({len(tier1)} experiments)\")\n",
    "    for key in tier1:\n",
    "        config = experiment_configs[key]\n",
    "        print(f\"   â€¢ {config['experiment_name']}\")\n",
    "        print(f\"     d_model={config['d_model']}, layers={config['num_layers']}, epochs={config['num_epochs']}\")\n",
    "\n",
    "if tier2:\n",
    "    print(f\"\\nğŸ”¬ TIER 2: Positional Encoding Ablation ({len(tier2)} experiments)\")\n",
    "    print(f\"   Baseline: tiny_d64 (sinusoidal)\")\n",
    "    for key in tier2:\n",
    "        config = experiment_configs[key]\n",
    "        print(f\"   â€¢ {config['experiment_name']}\")\n",
    "        print(f\"     PE={config['positional_encoding']}, d_model={config['d_model']}, epochs={config['num_epochs']}\")\n",
    "\n",
    "if tier3:\n",
    "    print(f\"\\nğŸ”¬ TIER 3: Flavor Conditioning Ablation ({len(tier3)} experiments)\")\n",
    "    print(f\"   Baseline: tiny_d64 (with flavors)\")\n",
    "    for key in tier3:\n",
    "        config = experiment_configs[key]\n",
    "        print(f\"   â€¢ {config['experiment_name']}\")\n",
    "        print(f\"     Flavors=False, d_model={config['d_model']}, epochs={config['num_epochs']}\")\n",
    "\n",
    "if tier4:\n",
    "    print(f\"\\nğŸ”¬ TIER 4: Debugging Comparison ({len(tier4)} experiments)\")\n",
    "    for key in tier4:\n",
    "        config = experiment_configs[key]\n",
    "        print(f\"   â€¢ {config['experiment_name']} âš ï¸  BROKEN\")\n",
    "        print(f\"     Normalization=False, d_model={config['d_model']}, epochs={config['num_epochs']}\")\n",
    "\n",
    "# Estimate time\n",
    "total_epochs = sum(c['num_epochs'] for c in experiment_configs.values())\n",
    "est_time_min = total_epochs * 0.8  # ~0.8 min per epoch on GPU\n",
    "print(f\"\\nâ±ï¸  Estimated total time: ~{est_time_min:.0f} min ({est_time_min/60:.1f} hours)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "for exp_name, config in experiment_configs.items():\n",
    "    os.makedirs(config['checkpoint_dir'], exist_ok=True)\n",
    "    os.makedirs(config['results_dir'], exist_ok=True)\n",
    "    print(f\"âœ… {config['experiment_name']}\")\n",
    "\n",
    "print(\"\\nâœ… All directories ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ RUN ALL EXPERIMENTS\n",
    "\n",
    "**This cell trains all enabled experiments**\n",
    "\n",
    "The trainer will automatically:\n",
    "- Load the correct data loader (normalized or not)\n",
    "- Initialize the correct architecture (PE type, flavors)\n",
    "- Train and save checkpoints\n",
    "- Apply early stopping if needed\n",
    "\n",
    "**Monitor progress**:\n",
    "- Epoch/total epochs\n",
    "- Train/val loss\n",
    "- Time per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# AUTOMATED EXPERIMENT RUNNER\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STARTING COMPREHENSIVE EXPERIMENTS\")\n",
    "print(f\"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for exp_idx, (exp_name, config) in enumerate(experiment_configs.items(), 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"EXPERIMENT {exp_idx}/{len(experiment_configs)}: {config['experiment_name'].upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nConfiguration:\")\n",
    "    print(f\"  d_model: {config['d_model']}\")\n",
    "    print(f\"  Layers: {config['num_layers']}\")\n",
    "    print(f\"  Positional Encoding: {config['positional_encoding']}\")\n",
    "    print(f\"  Flavors: {'âœ… Yes' if config.get('use_flavors', True) else 'âŒ No'}\")\n",
    "    print(f\"  Normalization: {'âœ… Yes' if config.get('use_normalization', True) else 'âŒ No (BROKEN)'}\")\n",
    "    print(f\"  Epochs: {config['num_epochs']}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n{'â”€'*80}\")\n",
    "        \n",
    "        # Import correct data loader\n",
    "        if config.get('use_normalization', True):\n",
    "            from src.dataset.preprocessed_data_loader_NORMALIZED import PreprocessedDataLoader\n",
    "            print(\"Data Loader: PreprocessedDataLoader_NORMALIZED âœ…\")\n",
    "        else:\n",
    "            from src.dataset.preprocessed_data_loader import PreprocessedDataLoader\n",
    "            print(\"Data Loader: PreprocessedDataLoader (BROKEN - no normalization) âŒ\")\n",
    "        \n",
    "        from train_transformer import TransformerTrainer\n",
    "        \n",
    "        print(\"Initializing trainer...\")\n",
    "        trainer = TransformerTrainer(config)\n",
    "        \n",
    "        print(\"Loading data...\")\n",
    "        trainer.load_data()\n",
    "        \n",
    "        print(\"Initializing model...\")\n",
    "        trainer.initialize_model()\n",
    "        \n",
    "        params = sum(p.numel() for p in trainer.model.parameters())\n",
    "        print(f\"Model parameters: {params:,}\")\n",
    "        \n",
    "        print(\"\\nStarting training...\")\n",
    "        print(f\"{'â”€'*80}\\n\")\n",
    "        trainer.train()\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        all_results[exp_name] = {\n",
    "            'config': config,\n",
    "            'training_time': elapsed_time,\n",
    "            'status': 'SUCCESS'\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'â”€'*80}\")\n",
    "        print(f\"âœ… Experiment {exp_idx} COMPLETE\")\n",
    "        print(f\"â±ï¸  Time: {elapsed_time/60:.1f} minutes\")\n",
    "        print(f\"{'â”€'*80}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"\\n{'â”€'*80}\")\n",
    "        print(f\"âŒ Experiment {exp_idx} FAILED\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        print(f\"{'â”€'*80}\\n\")\n",
    "        \n",
    "        all_results[exp_name] = {\n",
    "            'config': config,\n",
    "            'training_time': elapsed_time,\n",
    "            'status': 'FAILED',\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ALL EXPERIMENTS COMPLETE!\")\n",
    "print(f\"{'='*80}\")\n",
    "successful = sum(1 for r in all_results.values() if r['status'] == 'SUCCESS')\n",
    "print(f\"\\n  âœ… Successful: {successful}/{len(all_results)}\")\n",
    "print(f\"  â±ï¸  Total time: {sum(r['training_time'] for r in all_results.values())/60:.1f} minutes\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ LOAD & ANALYZE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all results\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "experiment_results = {}\n",
    "\n",
    "for exp_name, exp_data in all_results.items():\n",
    "    if exp_data['status'] != 'SUCCESS':\n",
    "        continue\n",
    "    \n",
    "    results_path = Path(exp_data['config']['results_dir']) / 'transformer_training_results.json'\n",
    "    \n",
    "    if results_path.exists():\n",
    "        with open(results_path, 'r') as f:\n",
    "            results = json.load(f)\n",
    "        experiment_results[exp_name] = results\n",
    "        print(f\"âœ… Loaded: {exp_name}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Total results loaded: {len(experiment_results)}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ COMPREHENSIVE COMPARISON TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# COMPREHENSIVE COMPARISON\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE RESULTS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "for exp_name, results in experiment_results.items():\n",
    "    config = results['config']\n",
    "    normalized = config.get('use_normalization', True)\n",
    "    \n",
    "    # Convert to RMSE in real temps\n",
    "    best_loss = results['best_val_loss']\n",
    "    if normalized:\n",
    "        rmse_norm = np.sqrt(best_loss)\n",
    "        rmse_real = rmse_norm * 400  # Denormalize\n",
    "    else:\n",
    "        rmse_real = np.sqrt(best_loss)\n",
    "    \n",
    "    row = {\n",
    "        'Experiment': exp_name,\n",
    "        'd_model': config['d_model'],\n",
    "        'Layers': config['num_layers'],\n",
    "        'Pos. Encoding': config['positional_encoding'],\n",
    "        'Flavors': 'âœ…' if config.get('use_flavors', True) else 'âŒ',\n",
    "        'Normalized': 'âœ…' if normalized else 'âŒ',\n",
    "        'Parameters': f\"{results['num_parameters']:,}\",\n",
    "        'Best RMSE (Â°F)': f\"{rmse_real:.1f}\",\n",
    "        'Final Epoch': results['final_epoch'],\n",
    "        'Time (min)': f\"{all_results[exp_name]['training_time']/60:.1f}\"\n",
    "    }\n",
    "    comparison_data.append(row)\n",
    "\n",
    "if comparison_data:\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Sort: broken last, then by RMSE\n",
    "    comparison_df['_rmse'] = comparison_df['Best RMSE (Â°F)'].astype(float)\n",
    "    comparison_df['_sort'] = comparison_df['Normalized'].apply(lambda x: 1 if x == 'âœ…' else 2)\n",
    "    comparison_df = comparison_df.sort_values(['_sort', '_rmse'])\n",
    "    comparison_df = comparison_df.drop(['_rmse', '_sort'], axis=1)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Highlight best\n",
    "    best = comparison_df[comparison_df['Normalized'] == 'âœ…'].iloc[0]\n",
    "    print(f\"\\nğŸ† BEST MODEL: {best['Experiment']}\")\n",
    "    print(f\"   RMSE: {best['Best RMSE (Â°F)']}Â°F\")\n",
    "    print(f\"   Config: d_model={best['d_model']}, PE={best['Pos. Encoding']}, flavors={best['Flavors']}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save\n",
    "os.makedirs('results', exist_ok=True)\n",
    "comparison_df.to_csv('results/comprehensive_comparison.csv', index=False)\n",
    "print(\"\\nâœ… Saved: results/comprehensive_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ ABLATION ANALYSIS: Positional Encoding\n",
    "\n",
    "**Compares**: Sinusoidal vs Learned vs RoPE (all d=64, with flavors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# POSITIONAL ENCODING ABLATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ABLATION STUDY: POSITIONAL ENCODING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filter: d=64, with flavors, normalized\n",
    "pe_exps = comparison_df[\n",
    "    (comparison_df['d_model'] == 64) &\n",
    "    (comparison_df['Flavors'] == 'âœ…') &\n",
    "    (comparison_df['Normalized'] == 'âœ…')\n",
    "].copy()\n",
    "\n",
    "if len(pe_exps) >= 2:\n",
    "    pe_exps = pe_exps.sort_values('Best RMSE (Â°F)')\n",
    "    \n",
    "    print(\"\\nğŸ“Š Positional Encoding Comparison (all d=64, with flavors):\\n\")\n",
    "    print(pe_exps[['Experiment', 'Pos. Encoding', 'Best RMSE (Â°F)', 'Final Epoch', 'Time (min)']].to_string(index=False))\n",
    "    \n",
    "    # Analysis\n",
    "    winner = pe_exps.iloc[0]\n",
    "    runner_up = pe_exps.iloc[1]\n",
    "    \n",
    "    improvement = float(runner_up['Best RMSE (Â°F)']) - float(winner['Best RMSE (Â°F)'])\n",
    "    \n",
    "    print(f\"\\nğŸ† Winner: {winner['Pos. Encoding'].upper()}\")\n",
    "    print(f\"   RMSE: {winner['Best RMSE (Â°F)']}Â°F\")\n",
    "    print(f\"   Improvement over {runner_up['Pos. Encoding']}: {improvement:.1f}Â°F\")\n",
    "    \n",
    "    if 'rope' in winner['Pos. Encoding'].lower():\n",
    "        print(\"\\nâœ¨ RoPE WINS! This validates your presentation topic!\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ Interpretation:\")\n",
    "    print(f\"   {winner['Pos. Encoding']} best captures temporal structure of roast profiles.\")\n",
    "    print(f\"   This validates the importance of positional encoding choice for time-series.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Need at least 2 PE experiments for comparison\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ ABLATION ANALYSIS: Flavor Conditioning\n",
    "\n",
    "**Tests your novel contribution**: Does flavor conditioning improve results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FLAVOR CONDITIONING ABLATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ABLATION STUDY: FLAVOR CONDITIONING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find with/without flavors (same config otherwise)\n",
    "with_flavors_exp = comparison_df[\n",
    "    (comparison_df['d_model'] == 64) &\n",
    "    (comparison_df['Pos. Encoding'] == 'sinusoidal') &\n",
    "    (comparison_df['Flavors'] == 'âœ…') &\n",
    "    (comparison_df['Normalized'] == 'âœ…')\n",
    "]\n",
    "\n",
    "without_flavors_exp = comparison_df[\n",
    "    (comparison_df['d_model'] == 64) &\n",
    "    (comparison_df['Pos. Encoding'] == 'sinusoidal') &\n",
    "    (comparison_df['Flavors'] == 'âŒ') &\n",
    "    (comparison_df['Normalized'] == 'âœ…')\n",
    "]\n",
    "\n",
    "if len(with_flavors_exp) > 0 and len(without_flavors_exp) > 0:\n",
    "    with_f = with_flavors_exp.iloc[0]\n",
    "    without_f = without_flavors_exp.iloc[0]\n",
    "    \n",
    "    comparison = pd.DataFrame({\n",
    "        'Configuration': ['With Flavors', 'Without Flavors'],\n",
    "        'Experiment': [with_f['Experiment'], without_f['Experiment']],\n",
    "        'RMSE (Â°F)': [with_f['Best RMSE (Â°F)'], without_f['Best RMSE (Â°F)']],\n",
    "        'Epochs': [with_f['Final Epoch'], without_f['Final Epoch']],\n",
    "        'Time': [with_f['Time (min)'], without_f['Time (min)']]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nğŸ“Š Flavor Feature Impact (d=64, sinusoidal):\\n\")\n",
    "    print(comparison.to_string(index=False))\n",
    "    \n",
    "    # Calculate impact\n",
    "    with_rmse = float(with_f['Best RMSE (Â°F)'])\n",
    "    without_rmse = float(without_f['Best RMSE (Â°F)'])\n",
    "    improvement = without_rmse - with_rmse\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ Analysis:\")\n",
    "    if improvement > 1.0:\n",
    "        print(f\"   âœ… Flavor features IMPROVED RMSE by {improvement:.1f}Â°F\")\n",
    "        print(f\"   This VALIDATES your novel contribution!\")\n",
    "        print(f\"   Flavor-guided generation provides meaningful signal.\")\n",
    "    elif improvement < -1.0:\n",
    "        print(f\"   âš ï¸  Flavor features WORSENED RMSE by {abs(improvement):.1f}Â°F\")\n",
    "        print(f\"   Possible explanations:\")\n",
    "        print(f\"   - Flavors may be redundant with origin/process\")\n",
    "        print(f\"   - Small dataset limits learning flavor relationships\")\n",
    "    else:\n",
    "        print(f\"   â†”ï¸  Flavor features had MINIMAL impact ({improvement:.1f}Â°F)\")\n",
    "        print(f\"   Flavors may correlate with but not cause temperature trajectories\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ For Presentation:\")\n",
    "    print(f\"   'We tested whether flavor profiles provide signal for generation.'\")\n",
    "    print(f\"   'Results: {abs(improvement):.1f}Â°F difference, suggesting flavors are'\")\n",
    "    if improvement > 1.0:\n",
    "        print(f\"   'a valuable conditioning signal for roast profile generation.'\")\n",
    "    else:\n",
    "        print(f\"   'largely captured by other features in this dataset.'\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Flavor ablation experiment not run\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if len(experiment_results) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Plot 1: All experiments\n",
    "    ax = axes[0, 0]\n",
    "    for exp_name, results in experiment_results.items():\n",
    "        config = results['config']\n",
    "        normalized = config.get('use_normalization', True)\n",
    "        linestyle = '-' if normalized else '--'\n",
    "        ax.plot(results['val_losses'], label=exp_name, linewidth=2, linestyle=linestyle)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Validation Loss')\n",
    "    ax.set_title('All Experiments', fontweight='bold')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Model size comparison\n",
    "    ax = axes[0, 1]\n",
    "    for exp_name in ['micro_d32', 'tiny_d64', 'medium_d128']:\n",
    "        if exp_name in experiment_results:\n",
    "            results = experiment_results[exp_name]\n",
    "            ax.plot(results['val_losses'], label=f\"d={results['config']['d_model']}\", linewidth=2)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Validation Loss')\n",
    "    ax.set_title('Model Size Comparison', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Positional encoding comparison\n",
    "    ax = axes[1, 0]\n",
    "    pe_map = {'tiny_d64': 'sinusoidal', 'learned_pe': 'learned', 'rope_pe': 'RoPE'}\n",
    "    for exp_name, label in pe_map.items():\n",
    "        if exp_name in experiment_results:\n",
    "            results = experiment_results[exp_name]\n",
    "            ax.plot(results['val_losses'], label=label, linewidth=2)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Validation Loss')\n",
    "    ax.set_title('Positional Encoding Ablation', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Flavor ablation\n",
    "    ax = axes[1, 1]\n",
    "    if 'tiny_d64' in experiment_results and 'no_flavors' in experiment_results:\n",
    "        ax.plot(experiment_results['tiny_d64']['val_losses'], label='With Flavors', linewidth=2)\n",
    "        ax.plot(experiment_results['no_flavors']['val_losses'], label='Without Flavors', linewidth=2)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Validation Loss')\n",
    "    ax.set_title('Flavor Conditioning Ablation', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/comprehensive_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… Saved: results/comprehensive_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ PACKAGE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package everything\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "package_name = f'roastformer_COMPREHENSIVE_{timestamp}.zip'\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PACKAGING COMPREHENSIVE RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "with zipfile.ZipFile(package_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    \n",
    "    # Results\n",
    "    if os.path.exists('results/comprehensive_comparison.csv'):\n",
    "        zipf.write('results/comprehensive_comparison.csv', 'comprehensive_comparison.csv')\n",
    "        print(\"âœ… comprehensive_comparison.csv\")\n",
    "    \n",
    "    if os.path.exists('results/comprehensive_analysis.png'):\n",
    "        zipf.write('results/comprehensive_analysis.png', 'comprehensive_analysis.png')\n",
    "        print(\"âœ… comprehensive_analysis.png\")\n",
    "    \n",
    "    # Checkpoints\n",
    "    for exp_name, exp_data in all_results.items():\n",
    "        if exp_data['status'] == 'SUCCESS':\n",
    "            checkpoint = Path(exp_data['config']['checkpoint_dir']) / 'best_transformer_model.pt'\n",
    "            if checkpoint.exists():\n",
    "                zipf.write(checkpoint, f'checkpoints/{exp_name}_model.pt')\n",
    "                print(f\"âœ… checkpoints/{exp_name}_model.pt\")\n",
    "    \n",
    "    # Results JSON\n",
    "    for exp_name, exp_data in all_results.items():\n",
    "        if exp_data['status'] == 'SUCCESS':\n",
    "            results_file = Path(exp_data['config']['results_dir']) / 'transformer_training_results.json'\n",
    "            if results_file.exists():\n",
    "                zipf.write(results_file, f'results/{exp_name}_results.json')\n",
    "    \n",
    "    # Summary\n",
    "    summary = f\"\"\"RoastFormer Comprehensive Experiment Results\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "COMPREHENSIVE ABLATION STUDIES\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Total Experiments: {len(all_results)}\n",
    "Successful: {sum(1 for r in all_results.values() if r['status'] == 'SUCCESS')}\n",
    "\n",
    "Study 1: Model Size (d=32 vs d=64 vs d=128)\n",
    "Study 2: Positional Encoding (sinusoidal vs learned vs RoPE)\n",
    "Study 3: Flavor Conditioning (with vs without flavors)\n",
    "Study 4: Debugging (broken vs fixed)\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "RESULTS SUMMARY\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "{comparison_df.to_string(index=False) if comparison_data else 'No results'}\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "KEY FINDINGS\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Best Model: {best['Experiment'] if comparison_data else 'N/A'}\n",
    "Configuration: d_model={best['d_model'] if comparison_data else 'N/A'}, {best['Pos. Encoding'] if comparison_data else 'N/A'} PE\n",
    "Performance: {best['Best RMSE (Â°F)'] if comparison_data else 'N/A'}Â°F RMSE\n",
    "\n",
    "For your presentation:\n",
    "1. Show positional encoding comparison (validates your RoPE presentation)\n",
    "2. Show flavor ablation (validates novel contribution)\n",
    "3. Show model size impact (demonstrates understanding of capacity)\n",
    "4. Show broken vs fixed (demonstrates debugging methodology)\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "FILES INCLUDED\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "1. comprehensive_comparison.csv - Full results table\n",
    "2. comprehensive_analysis.png - 4-panel visualization\n",
    "3. checkpoints/*.pt - All trained models\n",
    "4. results/*.json - Detailed training logs\n",
    "5. SUMMARY.txt - This file\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "NEXT STEPS\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "1. Use best checkpoint in evaluation demo\n",
    "2. Include ablation results in presentation\n",
    "3. Cite these experiments in methodology writeup\n",
    "4. Share with Claude for analysis and insights\n",
    "\"\"\"\n",
    "    \n",
    "    zipf.writestr('SUMMARY.txt', summary)\n",
    "    print(\"âœ… SUMMARY.txt\")\n",
    "\n",
    "print(f\"\\nğŸ“¦ Package: {package_name}\")\n",
    "print(f\"   Size: {os.path.getsize(package_name) / 1024 / 1024:.2f} MB\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading comprehensive results package...\")\n",
    "files.download(package_name)\n",
    "print(\"\\nâœ… Download complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Comprehensive Training Complete!\n",
    "\n",
    "### What You Have:\n",
    "\n",
    "1. âœ… **Complete ablation studies**:\n",
    "   - Model size comparison\n",
    "   - Positional encoding comparison (INCLUDING RoPE!)\n",
    "   - Flavor conditioning ablation\n",
    "   - Optional broken model comparison\n",
    "\n",
    "2. âœ… **Scientific validation**:\n",
    "   - RoPE performance (validates your presentation)\n",
    "   - Flavor impact (validates novel contribution)\n",
    "   - Model capacity effects\n",
    "\n",
    "3. âœ… **Presentation-ready materials**:\n",
    "   - Comparison tables\n",
    "   - 4-panel visualization\n",
    "   - Complete narrative\n",
    "\n",
    "### For Your Presentation:\n",
    "\n",
    "**Slide 1**: \"We compared three positional encoding methods...\"\n",
    "- Show PE ablation results\n",
    "- Highlight RoPE if it won\n",
    "- Connect to your RoPE presentation\n",
    "\n",
    "**Slide 2**: \"We tested our novel contribution: flavor-guided generation...\"\n",
    "- Show with/without flavors comparison\n",
    "- Quantify impact (XÂ°F improvement)\n",
    "- Discuss implications\n",
    "\n",
    "**Slide 3**: \"Model capacity matters, but regularization helps...\"\n",
    "- Show model size comparison\n",
    "- Discuss params/sample ratio\n",
    "- Justify tiny_d64 as production choice\n",
    "\n",
    "---\n",
    "\n",
    "**You now have a complete scientific study!** ğŸ¯ğŸ”¬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
