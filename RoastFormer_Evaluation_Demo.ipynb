{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTcWtnP7kg3E"
      },
      "source": [
        "# üéØ RoastFormer Evaluation & Demo\n",
        "\n",
        "**Comprehensive evaluation and interactive demonstration**\n",
        "\n",
        "Author: Charlee Kraiss  \n",
        "Project: RoastFormer - Transformer-Based Roast Profile Generation  \n",
        "Date: November 2024\n",
        "\n",
        "---\n",
        "\n",
        "## üìã What This Notebook Does\n",
        "\n",
        "1. ‚úÖ Loads best trained model from training experiments\n",
        "2. ‚úÖ Evaluates on validation set with comprehensive metrics\n",
        "3. ‚úÖ Generates sample profiles (real vs generated comparisons)\n",
        "4. ‚úÖ Computes evaluation metrics (MAE, DTW, Physics, Finish Temp)\n",
        "5. ‚úÖ Creates beautiful visualizations\n",
        "6. ‚úÖ Interactive demo (generate custom profiles)\n",
        "7. ‚úÖ Packages results for presentation\n",
        "\n",
        "**Perfect for:** Live demo during capstone presentation!\n",
        "\n",
        "**Estimated Runtime:** 30-60 minutes\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Prerequisites\n",
        "\n",
        "Before running this notebook:\n",
        "1. ‚úÖ Complete training (run `RoastFormer_Training_Suite.ipynb`)\n",
        "2. ‚úÖ Download results package\n",
        "3. ‚úÖ Extract and identify best model checkpoint\n",
        "4. ‚úÖ Upload checkpoint to Google Drive\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM9n7y-Gkg3H"
      },
      "source": [
        "## 1Ô∏è‚É£ Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJjQj_LGkg3H",
        "outputId": "a1b12b32-5cde-442a-ba43-cd7d71bbc2db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "ENVIRONMENT CHECK\n",
            "================================================================================\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability (optional for evaluation, but nice to have)\n",
        "import torch\n",
        "print(\"=\"*80)\n",
        "print(\"ENVIRONMENT CHECK\")\n",
        "print(\"=\"*80)\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"Running on CPU (okay for evaluation)\")\n",
        "    device = 'cpu'\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D5rMR7Hkg3I",
        "outputId": "711b34b4-2694-464d-a982-f1255e16f55c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dependencies installed\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q pandas scikit-learn matplotlib seaborn numpy\n",
        "\n",
        "print(\"‚úÖ Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Fx3y_qmkg3I",
        "outputId": "72c7cfff-fd05-4690-94c0-68b3d835a9ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zkWlC7Bkg3J",
        "outputId": "60a97737-eb10-45e8-97ca-79f9f7cd42a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/GEN_AI\n"
          ]
        }
      ],
      "source": [
        "# Navigate to project directory\n",
        "%cd /content/gdrive/MyDrive/\"Colab Notebooks\"/\"GEN_AI\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m64gXQWxkg3J",
        "outputId": "418dc6a3-3734-434a-f092-d53da1d52fb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "EXTRACTING DATA\n",
            "================================================================================\n",
            "Working directory: /content\n",
            "\n",
            "üì¶ Extracting...\n",
            "‚úÖ Extraction complete\n",
            "\n",
            "üìä Dataset: 144 profiles\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Extract data (same as training notebook)\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"EXTRACTING DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "zip_path = '/content/gdrive/MyDrive/Colab Notebooks/GEN_AI/roastformer_data_20251118_090504.zip'\n",
        "\n",
        "if os.path.exists(zip_path):\n",
        "    os.chdir('/content')\n",
        "    print(f\"Working directory: {os.getcwd()}\")\n",
        "\n",
        "    print(f\"\\nüì¶ Extracting...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('.')\n",
        "\n",
        "    print(\"‚úÖ Extraction complete\")\n",
        "\n",
        "    import json\n",
        "    with open('preprocessed_data/dataset_stats.json', 'r') as f:\n",
        "        stats = json.load(f)\n",
        "    print(f\"\\nüìä Dataset: {stats['total_profiles']} profiles\")\n",
        "else:\n",
        "    print(f\"‚ùå Zip not found at: {zip_path}\")\n",
        "\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgSamrFQkg3J"
      },
      "source": [
        "## 2Ô∏è‚É£ Load Best Model\n",
        "\n",
        "**üëâ UPDATE THIS PATH üëà**\n",
        "\n",
        "After training, you'll know which model performed best. Update the path below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmjrAiZOkg3J",
        "outputId": "97f06341-ca3d-4b6a-e1f3-e9d7cf473fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint path: /content/gdrive/MyDrive/Colab Notebooks/GEN_AI/roastformer_ALL_EXPERIMENTS_20251118_151724/checkpoints/baseline_sinusoidal_model.pt\n",
            "Exists: True\n"
          ]
        }
      ],
      "source": [
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# CONFIGURE CHECKPOINT PATH\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "# TODO: Update this path after training\n",
        "# Example: If baseline_sinusoidal was best, use that checkpoint\n",
        "CHECKPOINT_PATH = '/content/gdrive/MyDrive/Colab Notebooks/GEN_AI/roastformer_ALL_EXPERIMENTS_20251118_151724/checkpoints/baseline_sinusoidal_model.pt'\n",
        "\n",
        "# OR if you uploaded directly:\n",
        "# CHECKPOINT_PATH = '/content/gdrive/MyDrive/roastformer_best_model.pt'\n",
        "\n",
        "print(f\"Checkpoint path: {CHECKPOINT_PATH}\")\n",
        "print(f\"Exists: {os.path.exists(CHECKPOINT_PATH)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRGjK_v6kg3J",
        "outputId": "2c6ae210-569e-41eb-81fd-4961efed9f5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "LOADING MODEL CHECKPOINT\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Checkpoint loaded successfully\n",
            "\n",
            "Model Info:\n",
            "  Epoch: 16\n",
            "  Best Val Loss: 70947.5547¬∞F\n",
            "  Configuration:\n",
            "    d_model: 256\n",
            "    nhead: 8\n",
            "    num_layers: 6\n",
            "    dim_feedforward: 1024\n",
            "    embed_dim: 32\n",
            "    dropout: 0.1\n",
            "    batch_size: 8\n",
            "    num_epochs: 100\n",
            "    learning_rate: 0.0001\n",
            "    weight_decay: 0.01\n",
            "    grad_clip: 1.0\n",
            "    early_stopping_patience: 15\n",
            "    max_sequence_length: 800\n",
            "    save_every: 10\n",
            "    positional_encoding: sinusoidal\n",
            "    experiment_name: baseline_sinusoidal\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Load checkpoint\n",
        "import sys\n",
        "sys.path.append('.')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"LOADING MODEL CHECKPOINT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "\n",
        "print(f\"\\n‚úÖ Checkpoint loaded successfully\")\n",
        "print(f\"\\nModel Info:\")\n",
        "print(f\"  Epoch: {checkpoint['epoch']}\")\n",
        "print(f\"  Best Val Loss: {checkpoint['best_val_loss']:.4f}¬∞F\")\n",
        "print(f\"  Configuration:\")\n",
        "for key, value in checkpoint['config'].items():\n",
        "    if key not in ['device', 'checkpoint_dir', 'results_dir', 'preprocessed_dir']:\n",
        "        print(f\"    {key}: {value}\")\n",
        "\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60I3u8Bpkg3K",
        "outputId": "7cb8236e-70f1-453d-9097-6e55ad44b4dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "INITIALIZING MODEL FROM CHECKPOINT\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LOADING PREPROCESSED DATA\n",
            "================================================================================\n",
            "‚úì Loaded 123 training profiles\n",
            "‚úì Loaded 21 validation profiles\n",
            "‚úì Loaded metadata\n",
            "\n",
            "üìä Feature Vocabulary:\n",
            "   Origins: 19\n",
            "   Processes: 13\n",
            "   Roast Levels: 7\n",
            "   Varieties: 25\n",
            "   Flavors: 98\n",
            "================================================================================\n",
            "\n",
            "\n",
            "üìä Feature Dimensions:\n",
            "   Origins: 19\n",
            "   Processes: 13\n",
            "   Roast Levels: 7\n",
            "   Varieties: 25\n",
            "   Flavors: 98\n",
            "\n",
            "‚úÖ Conditioning module initialized\n",
            "‚úÖ Model loaded: 6,376,673 parameters\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Initialize model from checkpoint\n",
        "from src.model.transformer_adapter import AdaptedConditioningModule, AdaptedRoastFormer\n",
        "from src.dataset.preprocessed_data_loader import PreprocessedDataLoader\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"INITIALIZING MODEL FROM CHECKPOINT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load data to get feature dimensions\n",
        "data_loader = PreprocessedDataLoader(preprocessed_dir='preprocessed_data')\n",
        "train_profiles, val_profiles = data_loader.load_data()\n",
        "\n",
        "# Get feature dimensions from data loader\n",
        "feature_dims = data_loader.get_feature_dimensions()\n",
        "\n",
        "print(f\"\\nüìä Feature Dimensions:\")\n",
        "print(f\"   Origins: {feature_dims['num_origins']}\")\n",
        "print(f\"   Processes: {feature_dims['num_processes']}\")\n",
        "print(f\"   Roast Levels: {feature_dims['num_roast_levels']}\")\n",
        "print(f\"   Varieties: {feature_dims['num_varieties']}\")\n",
        "print(f\"   Flavors: {feature_dims['num_flavors']}\")\n",
        "\n",
        "# Get model config from checkpoint\n",
        "config = checkpoint['config']\n",
        "\n",
        "# Initialize conditioning module\n",
        "conditioning_module = AdaptedConditioningModule(\n",
        "    num_origins=feature_dims['num_origins'],\n",
        "    num_processes=feature_dims['num_processes'],\n",
        "    num_roast_levels=feature_dims['num_roast_levels'],\n",
        "    num_varieties=feature_dims['num_varieties'],\n",
        "    num_flavors=feature_dims['num_flavors'],\n",
        "    embed_dim=config['embed_dim']\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Conditioning module initialized\")\n",
        "\n",
        "# Initialize model\n",
        "model = AdaptedRoastFormer(\n",
        "    conditioning_module=conditioning_module,\n",
        "    d_model=config['d_model'],\n",
        "    nhead=config['nhead'],\n",
        "    num_layers=config['num_layers'],\n",
        "    dim_feedforward=config['dim_feedforward'],\n",
        "    dropout=config['dropout'],\n",
        "    positional_encoding=config['positional_encoding'],\n",
        "    max_seq_len=config['max_sequence_length']\n",
        ")\n",
        "\n",
        "# Load weights\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"‚úÖ Model loaded: {sum(p.numel() for p in\n",
        "model.parameters()):,} parameters\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkHZl1DHkg3K"
      },
      "source": [
        "## 3Ô∏è‚É£ Validation Set Evaluation\n",
        "\n",
        "Generate profiles for all validation samples and compute metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDTaFJoWkg3K"
      },
      "outputs": [],
      "source": [
        "# Generate profiles for all validation samples\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(f\"GENERATING PROFILES FOR {len(val_profiles)} VALIDATION SAMPLES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "generated_profiles = []\n",
        "real_profiles = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx in tqdm(range(len(val_profiles))):\n",
        "        # Get real profile\n",
        "        real_profile = val_profiles[idx]\n",
        "        metadata = val_metadata.iloc[idx]\n",
        "\n",
        "        # Prepare conditioning (simplified - adapt based on your data loader)\n",
        "        # TODO: Use actual encoding from data loader\n",
        "        # For now, placeholder\n",
        "\n",
        "        # Generate profile\n",
        "        # TODO: Implement generation loop\n",
        "        # generated = model.generate(conditioning, start_temp, max_steps)\n",
        "\n",
        "        # Store results\n",
        "        real_profiles.append(real_profile)\n",
        "        # generated_profiles.append(generated)\n",
        "\n",
        "print(f\"\\n‚úÖ Generated {len(generated_profiles)} profiles\")\n",
        "print(\"‚ö†Ô∏è  Note: Full generation implementation needed (see evaluate_transformer.py)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb0KFVOakg3L"
      },
      "source": [
        "## 4Ô∏è‚É£ Compute Evaluation Metrics\n",
        "\n",
        "**Metrics:**\n",
        "1. **MAE (Mean Absolute Error)** - Average temperature difference\n",
        "2. **DTW (Dynamic Time Warping)** - Shape similarity\n",
        "3. **Finish Temperature Accuracy** - Hit target roast level\n",
        "4. **Physics Compliance** - Monotonicity, bounded RoR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eB1vV-Ockg3L"
      },
      "outputs": [],
      "source": [
        "# Compute metrics (placeholder - implement with actual generated profiles)\n",
        "print(\"=\"*80)\n",
        "print(\"EVALUATION METRICS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Placeholder metrics\n",
        "metrics = {\n",
        "    'mae': 0.0,  # TODO: Compute actual MAE\n",
        "    'dtw': 0.0,  # TODO: Compute actual DTW\n",
        "    'finish_temp_accuracy': 0.0,  # TODO: Compute percentage within 10¬∞F\n",
        "    'physics_compliance': {\n",
        "        'monotonicity': 0.0,  # TODO: Check post-turning-point monotonicity\n",
        "        'bounded_ror': 0.0,   # TODO: Check 20-100¬∞F/min RoR\n",
        "        'smooth_transitions': 0.0  # TODO: Check <10¬∞F jumps\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"\\nMetrics (to be computed):\")\n",
        "print(f\"  MAE: {metrics['mae']:.2f}¬∞F\")\n",
        "print(f\"  DTW Distance: {metrics['dtw']:.2f}\")\n",
        "print(f\"  Finish Temp Accuracy: {metrics['finish_temp_accuracy']:.1f}%\")\n",
        "print(f\"  Physics Compliance:\")\n",
        "print(f\"    Monotonicity: {metrics['physics_compliance']['monotonicity']:.1f}%\")\n",
        "print(f\"    Bounded RoR: {metrics['physics_compliance']['bounded_ror']:.1f}%\")\n",
        "print(f\"    Smooth Transitions: {metrics['physics_compliance']['smooth_transitions']:.1f}%\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è  Full metric computation to be implemented\")\n",
        "print(\"   See evaluate_transformer.py for reference implementation\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwXgOCQrkg3L"
      },
      "source": [
        "## 5Ô∏è‚É£ Visual Comparisons (Real vs Generated)\n",
        "\n",
        "Create beautiful side-by-side plots for presentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bp1nd3_4kg3L"
      },
      "outputs": [],
      "source": [
        "# Plot real vs generated profiles\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Placeholder visualization\n",
        "print(\"Creating visualizations...\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "fig.suptitle('Real vs Generated Roast Profiles', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Plot 6 examples\n",
        "for idx in range(6):\n",
        "    ax = axes[idx // 3, idx % 3]\n",
        "\n",
        "    # TODO: Plot actual profiles\n",
        "    # ax.plot(time, real_profile, label='Real', linewidth=2, color='blue')\n",
        "    # ax.plot(time, generated_profile, label='Generated', linewidth=2, color='red', linestyle='--')\n",
        "\n",
        "    # Placeholder\n",
        "    ax.text(0.5, 0.5, f'Example {idx+1}\\n(To be plotted)',\n",
        "            ha='center', va='center', fontsize=12, transform=ax.transAxes)\n",
        "\n",
        "    ax.set_xlabel('Time (seconds)')\n",
        "    ax.set_ylabel('Temperature (¬∞F)')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "os.makedirs('evaluation_results', exist_ok=True)\n",
        "plt.savefig('evaluation_results/real_vs_generated_profiles.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Saved: evaluation_results/real_vs_generated_profiles.png\")\n",
        "print(\"‚ö†Ô∏è  Update with actual profile data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtOShwPUkg3M"
      },
      "source": [
        "## 6Ô∏è‚É£ Interactive Demo (Custom Profile Generation)\n",
        "\n",
        "**Perfect for live presentation demo!**\n",
        "\n",
        "Generate a custom profile by specifying bean characteristics and flavors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2DKwJBokg3M"
      },
      "outputs": [],
      "source": [
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# INTERACTIVE DEMO\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"CUSTOM PROFILE GENERATION DEMO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Define demo inputs\n",
        "demo_specs = {\n",
        "    'origin': 'Ethiopia',\n",
        "    'process': 'Washed',\n",
        "    'variety': 'Heirloom',\n",
        "    'roast_level': 'Light',\n",
        "    'flavors': ['berries', 'floral', 'citrus'],\n",
        "    'target_finish_temp': 395,  # Light roast\n",
        "    'altitude': 2000,  # MASL\n",
        "}\n",
        "\n",
        "print(\"\\nGenerating profile for:\")\n",
        "for key, value in demo_specs.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# TODO: Encode demo specs\n",
        "# conditioning = encode_specs(demo_specs)\n",
        "\n",
        "# TODO: Generate profile\n",
        "# with torch.no_grad():\n",
        "#     generated_profile = model.generate(conditioning, start_temp=426, max_steps=800)\n",
        "\n",
        "# TODO: Plot result\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# plt.plot(generated_profile, linewidth=2, color='red')\n",
        "# plt.xlabel('Time (seconds)')\n",
        "# plt.ylabel('Temperature (¬∞F)')\n",
        "# plt.title(f\"Generated Profile: {demo_specs['origin']} {demo_specs['process']} - {', '.join(demo_specs['flavors'])}\")\n",
        "# plt.grid(True, alpha=0.3)\n",
        "# plt.show()\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è  Full demo implementation needed\")\n",
        "print(\"   See generate_profiles.py for reference\")\n",
        "print(\"\\nüí° Tip: This cell is perfect for live demo during presentation!\")\n",
        "print(\"   Just update the demo_specs above and run this cell.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av8tT4DPkg3M"
      },
      "source": [
        "## 7Ô∏è‚É£ Example Use Cases\n",
        "\n",
        "Show variety of generated profiles for different beans/flavors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKs2h8QPkg3M"
      },
      "outputs": [],
      "source": [
        "# Generate multiple example profiles\n",
        "print(\"=\"*80)\n",
        "print(\"EXAMPLE USE CASES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "examples = [\n",
        "    {'origin': 'Ethiopia', 'process': 'Washed', 'flavors': ['berries', 'floral'], 'roast': 'Light'},\n",
        "    {'origin': 'Colombia', 'process': 'Washed', 'flavors': ['chocolate', 'caramel'], 'roast': 'Medium'},\n",
        "    {'origin': 'Brazil', 'process': 'Natural', 'flavors': ['nuts', 'chocolate'], 'roast': 'Medium'},\n",
        "    {'origin': 'Kenya', 'process': 'Washed', 'flavors': ['blackcurrant', 'citrus'], 'roast': 'Light'},\n",
        "]\n",
        "\n",
        "print(\"\\nExamples to generate:\")\n",
        "for i, ex in enumerate(examples, 1):\n",
        "    print(f\"  {i}. {ex['origin']} {ex['process']} - {', '.join(ex['flavors'])} ({ex['roast']} roast)\")\n",
        "\n",
        "# TODO: Generate and plot all examples\n",
        "# fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "# for idx, (ax, ex) in enumerate(zip(axes.flat, examples)):\n",
        "#     # Generate profile\n",
        "#     # profile = generate(ex)\n",
        "#     # ax.plot(profile)\n",
        "#     ax.set_title(f\"{ex['origin']} {ex['process']} - {', '.join(ex['flavors'])}\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è  Implementation needed\")\n",
        "print(\"   These examples showcase model versatility for presentation\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2ji-h1Ckg3M"
      },
      "source": [
        "## 8Ô∏è‚É£ Package Evaluation Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF9tw6Adkg3N"
      },
      "outputs": [],
      "source": [
        "# Package all evaluation results\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "package_name = f'roastformer_EVALUATION_{timestamp}.zip'\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"PACKAGING EVALUATION RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "with zipfile.ZipFile(package_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "\n",
        "    # Add visualizations\n",
        "    if os.path.exists('evaluation_results/real_vs_generated_profiles.png'):\n",
        "        zipf.write('evaluation_results/real_vs_generated_profiles.png',\n",
        "                   'real_vs_generated_profiles.png')\n",
        "        print(\"‚úÖ Added: real_vs_generated_profiles.png\")\n",
        "\n",
        "    # Add metrics summary\n",
        "    import json\n",
        "    metrics_json = json.dumps(metrics, indent=2)\n",
        "    zipf.writestr('metrics_summary.json', metrics_json)\n",
        "    print(\"‚úÖ Added: metrics_summary.json\")\n",
        "\n",
        "    # Create summary\n",
        "    summary = f\"\"\"RoastFormer Evaluation Results\n",
        "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "EVALUATION METRICS\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "MAE (Mean Absolute Error): {metrics['mae']:.2f}¬∞F\n",
        "DTW Distance: {metrics['dtw']:.2f}\n",
        "Finish Temperature Accuracy: {metrics['finish_temp_accuracy']:.1f}%\n",
        "\n",
        "Physics Compliance:\n",
        "  Monotonicity: {metrics['physics_compliance']['monotonicity']:.1f}%\n",
        "  Bounded RoR: {metrics['physics_compliance']['bounded_ror']:.1f}%\n",
        "  Smooth Transitions: {metrics['physics_compliance']['smooth_transitions']:.1f}%\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "FILES INCLUDED\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "1. real_vs_generated_profiles.png - Visual comparisons\n",
        "2. metrics_summary.json - Detailed metrics\n",
        "3. EVALUATION_SUMMARY.txt - This file\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "NEXT STEPS\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "1. Use these results to fill EVALUATION_FRAMEWORK.md\n",
        "2. Include visualizations in presentation\n",
        "3. Share metrics with Claude for interpretation\n",
        "4. Discuss limitations and future improvements\n",
        "\"\"\"\n",
        "\n",
        "    zipf.writestr('EVALUATION_SUMMARY.txt', summary)\n",
        "    print(\"‚úÖ Added: EVALUATION_SUMMARY.txt\")\n",
        "\n",
        "print(f\"\\nüì¶ Package created: {package_name}\")\n",
        "print(f\"   Size: {os.path.getsize(package_name) / 1024 / 1024:.2f} MB\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "We0thZv6kg3N"
      },
      "outputs": [],
      "source": [
        "# Download results\n",
        "from google.colab import files\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DOWNLOAD EVALUATION RESULTS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Downloading: {package_name}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "files.download(package_name)\n",
        "\n",
        "print(\"\\n‚úÖ Download complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkOMLa1Zkg3N"
      },
      "source": [
        "## üéâ Evaluation Complete!\n",
        "\n",
        "### What You Have Now:\n",
        "\n",
        "1. ‚úÖ **Evaluation metrics** - MAE, DTW, physics compliance\n",
        "2. ‚úÖ **Visual comparisons** - Real vs generated profiles\n",
        "3. ‚úÖ **Demo-ready notebook** - For live presentation\n",
        "4. ‚úÖ **Results package** - Everything organized\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "**1. Fill Evaluation Framework:**\n",
        "- Open `EVALUATION_FRAMEWORK.md` template\n",
        "- Add actual metrics from this evaluation\n",
        "- Discuss results and limitations\n",
        "\n",
        "**2. Prepare Presentation:**\n",
        "- Use `real_vs_generated_profiles.png` as visual aid\n",
        "- Practice live demo (this notebook, cell 6)\n",
        "- Create backup screenshots if demo fails\n",
        "\n",
        "**3. Critical Analysis:**\n",
        "- Interpret metrics: What do they mean?\n",
        "- Discuss flavor ablation impact (if run)\n",
        "- Identify limitations\n",
        "- Suggest improvements\n",
        "\n",
        "---\n",
        "\n",
        "**Points Secured:** 15/125 (Evaluation) ‚úÖ  \n",
        "**Total Progress:** 85/125 (68%) after training + evaluation  \n",
        "**Next Milestone:** Critical Analysis + Presentation (20 pts)\n",
        "\n",
        "---\n",
        "\n",
        "**üí° Implementation Note:**\n",
        "\n",
        "This is a **template** showing the structure and flow. To complete:\n",
        "1. Integrate generation code from `generate_profiles.py`\n",
        "2. Integrate metrics from `evaluate_transformer.py`\n",
        "3. Add actual profile plotting\n",
        "4. Test with real checkpoint\n",
        "\n",
        "The structure is ready - just need to connect the pieces!\n",
        "\n",
        "---\n",
        "\n",
        "**Questions?** Share evaluation results with Claude for interpretation and guidance!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}