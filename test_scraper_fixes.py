"""
Quick test script to verify Onyx scraper fixes
Tests the fixed scraper on a single product and shows what was extracted
"""

import sys
import json
from onyx_dataset_builder_v3_3_COMBINED import OnyxDatasetBuilderV3

def test_single_product(url):
    """
    Test scraping a single product and show detailed extraction results
    """
    print("="*80)
    print("TESTING ONYX SCRAPER FIXES")
    print("="*80)
    print(f"\nTest URL: {url}")
    print("\n" + "-"*80)
    
    # Initialize builder (use_date_suffix=False for testing)
    builder = OnyxDatasetBuilderV3(output_dir='test_scrape', use_date_suffix=False)
    
    # Scrape the product
    print("\nüì° Scraping product...")
    result = builder.scrape_roast_profile(url)
    
    if not result:
        print("\n‚ùå SCRAPING FAILED")
        return
    
    metadata = result.get('metadata', {})
    
    print("\n" + "="*80)
    print("EXTRACTION RESULTS")
    print("="*80)
    
    # Check critical fields
    print("\nüè∑Ô∏è  PRODUCT NAME:")
    product_name = metadata.get('product_name', 'NOT FOUND')
    print(f"   Value: '{product_name}'")
    
    # Check for character spacing issue
    if ' ' in product_name and len(product_name.replace(' ', '')) < len(product_name) / 2:
        print("   ‚ö†Ô∏è  WARNING: Product name still has character spacing!")
    else:
        print("   ‚úÖ OK - No character spacing issues")
    
    print("\nüåç ORIGIN:")
    origin = metadata.get('origin', 'NOT FOUND')
    print(f"   Value: '{origin}'")
    print(f"   Status: {'‚úÖ FOUND' if origin != 'NOT FOUND' else '‚ùå MISSING'}")
    
    print("\n‚öóÔ∏è  PROCESS METHOD:")
    process = metadata.get('process', 'NOT FOUND')
    print(f"   Value: '{process}'")
    print(f"   Status: {'‚úÖ FOUND' if process != 'NOT FOUND' else '‚ùå MISSING'}")
    
    print("\n‚òï ROAST LEVEL:")
    roast = metadata.get('roast_level', 'NOT FOUND')
    agtron = metadata.get('roast_level_agtron', 'N/A')
    print(f"   Level: '{roast}'")
    print(f"   Agtron: {agtron}")
    print(f"   Status: {'‚úÖ FOUND' if roast != 'NOT FOUND' else '‚ùå MISSING'}")
    
    print("\nüé® FLAVOR NOTES:")
    flavor_raw = metadata.get('flavor_notes_raw')
    flavor_parsed = metadata.get('flavor_notes_parsed')
    flavor_cats = metadata.get('flavor_categories')
    
    if flavor_raw:
        print(f"   Raw: '{flavor_raw}'")
        print(f"   Parsed: {flavor_parsed}")
        print(f"   Categories: {flavor_cats}")
        print("   ‚úÖ FLAVORS EXTRACTED!")
    else:
        print("   ‚ùå NO FLAVORS FOUND")
    
    print("\nüåæ VARIETY:")
    variety = metadata.get('variety', 'NOT FOUND')
    print(f"   Value: '{variety}'")
    print(f"   Status: {'‚úÖ FOUND' if variety != 'NOT FOUND' else '‚ùå MISSING'}")
    
    print("\n‚õ∞Ô∏è  ALTITUDE:")
    altitude = metadata.get('altitude', 'NOT FOUND')
    altitude_num = metadata.get('altitude_numeric')
    print(f"   Value: '{altitude}'")
    if altitude_num:
        print(f"   Numeric: {altitude_num}m")
    print(f"   Status: {'‚úÖ FOUND' if altitude != 'NOT FOUND' else '‚ùå MISSING'}")
    
    print("\nüìä ROAST PROFILE:")
    roast_profile = result.get('roast_profile', {})
    if 'bean_temp' in roast_profile:
        bean_data = roast_profile['bean_temp']
        print(f"   Bean Temp: {len(bean_data)} points")
        if bean_data:
            print(f"   Start: {bean_data[0].get('value', 'N/A')}¬∞F at {bean_data[0].get('time', 'N/A')}s")
            print(f"   End: {bean_data[-1].get('value', 'N/A')}¬∞F at {bean_data[-1].get('time', 'N/A')}s")
            
            # Show first 10 and last 10 points for verification
            print(f"\n   üìà First 10 data points:")
            for point in bean_data[:10]:
                print(f"      Time {point.get('time')}s: {point.get('value')}¬∞F")
            
            print(f"\n   üìà Last 10 data points:")
            for point in bean_data[-10:]:
                print(f"      Time {point.get('time')}s: {point.get('value')}¬∞F")
            
        print("   ‚úÖ PROFILE DATA EXTRACTED")
    else:
        print("   ‚ùå NO PROFILE DATA FOUND")
    
    # Summary
    print("\n" + "="*80)
    print("SUMMARY")
    print("="*80)
    
    critical_fields = {
        'Product Name': product_name != 'NOT FOUND',
        'Origin': origin != 'NOT FOUND',
        'Process': process != 'NOT FOUND',
        'Flavors': flavor_raw is not None,
        'Roast Level': roast != 'NOT FOUND',
        'Profile Data': 'bean_temp' in roast_profile
    }
    
    found_count = sum(critical_fields.values())
    total_count = len(critical_fields)
    
    print(f"\nCritical Fields Found: {found_count}/{total_count}")
    
    for field, found in critical_fields.items():
        status = "‚úÖ" if found else "‚ùå"
        print(f"  {status} {field}")
    
    if found_count == total_count:
        print("\nüéâ ALL CRITICAL FIELDS EXTRACTED SUCCESSFULLY!")
    elif found_count >= total_count * 0.7:
        print("\n‚ö†Ô∏è  Most fields extracted, but some are missing")
    else:
        print("\n‚ùå SCRAPER NEEDS MORE FIXES")
    
    # Save detailed results INCLUDING FULL ROAST PROFILE
    output_file = "test_scrape/test_results.json"
    with open(output_file, 'w') as f:
        json.dump({
            'url': url,
            'metadata': metadata,
            'roast_profile': result.get('roast_profile', {}),  # FULL profile data
            'summary': result.get('summary', {}),  # Profile summary stats
            'critical_fields': critical_fields
        }, f, indent=2, default=str)
    
    print(f"\nüìÑ Detailed results saved to: {output_file}")
    print("="*80)


if __name__ == "__main__":
    # Default test URL (Geometry)
    test_url = "https://onyxcoffeelab.com/products/geometry?variant=31862717677666"
    
    # Allow custom URL from command line
    if len(sys.argv) > 1:
        test_url = sys.argv[1]
    
    test_single_product(test_url)